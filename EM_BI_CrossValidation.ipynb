{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2bbb12-38d4-4004-87f5-66dc4adc4bdf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea2c7a-c252-4290-91ce-23c32b3e5df9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%run ./EM_BI_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b1b3b-41f0-467c-9b11-268eb661d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for segments division\n",
    "segment_length=100\n",
    "segment_number=3\n",
    "data_part= segment_length * segment_number\n",
    "\n",
    "# Name of the column wich contains x coordinate\n",
    "col='x'\n",
    "\n",
    "# Number of jumping points to analyze\n",
    "lp=50\n",
    "\n",
    "# Session settings\n",
    "# Number of participants\n",
    "class_nb=14\n",
    "\n",
    "# Number of sessions \n",
    "lb_sessions=9 \n",
    "\n",
    "# Number of columns for data series set - user, session, trail, 7 data features\n",
    "col_number=10\n",
    "\n",
    "# Number of column for statistical features - user, session, trail, 16 data features\n",
    "flat_col_number=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f508b63-4e80-472f-8e4c-97de268de684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings for data folder and results folder\n",
    "\n",
    "# Assumption: data from GazeBase set are extracted into folder Random_Saccades_<sessions_number>, \n",
    "# each round data are stored in separate subfolder Round_<round_number>, \n",
    "# for example: Random_Saccades_9/Round_1\n",
    "\n",
    "# Data folder\n",
    "root_folder=\"../data/Random_Saccades_\"+str(lb_sessions)\n",
    "\n",
    "# Results folder \n",
    "# results in the form of a CSV file with information on accuracy, F1 score, and Cohen's Kappa for each LOSO iteration\n",
    "output_dir=\"../results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fb0d3-6d7b-4b7a-8918-6e3677d2ea4f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loading and features calculation\n",
    "f_values_all=pd.DataFrame()\n",
    "f_series_all=pd.DataFrame()\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "\n",
    "    for file in filenames:\n",
    "        print(file)\n",
    "        file_name=file.split('.')[0]\n",
    "        session, label, trial = file_name.split('_')[1][0],  file_name.split('_')[1][1:4], file_name.split('_')[2]\n",
    "       \n",
    "        eye_data = pd.read_csv(os.path.join(dirpath, file),header=0, sep=',') \n",
    "        xyT_df=eye_data.iloc[:,[4,5]]\n",
    "        \n",
    "        xTu_df= xyT_df['xT'].unique()\n",
    "        yTu_df= xyT_df['yT'].unique()\n",
    "        eye_point=pd.DataFrame()\n",
    "        eye_set=pd.DataFrame( )\n",
    "\n",
    "        l_points=0\n",
    "          \n",
    "        for x in range(xTu_df.shape[0]):\n",
    "            for y in range(yTu_df.shape[0]):\n",
    "                point_feature_series=pd.DataFrame([[session, int(label), trial]]*segment_number*(segment_length), columns =['session', 'label', 'trial'])\n",
    "                point_feature_values=pd.DataFrame([[session, int(label), trial]]*segment_number, columns =['session', 'label', 'trial'])\n",
    "           \n",
    "                if trial=='S1':\n",
    "                    l_rows=eye_data[(eye_data['xT']==xTu_df[x]) & (eye_data['yT']==yTu_df[y])].shape[0]\n",
    "            \n",
    "                    if (l_rows>0):\n",
    "                        if not (eye_data[(eye_data['xT']==xTu_df[x]) & (eye_data['yT']==yTu_df[y])]['x'].isna().any()):\n",
    "                    \n",
    "                            eye_point_all=eye_data[(eye_data['xT']==xTu_df[x]) & (eye_data['yT']==yTu_df[y])]\n",
    "                            if (l_points<lp): # so that all participants have the same number of points\n",
    "                                l_points+=1\n",
    "                                \n",
    "                                eye_subset=eye_point_all.iloc[0:data_part+4,[1, 4, 5]]\n",
    "                                \n",
    "                                # feature extraction for entire data segments\n",
    "                                eye_v=pd.DataFrame(eye_v_f(eye_subset.iloc[:,0], data_part+4), columns=['v'+str(col)]).reset_index(drop=True)\n",
    "                                eye_a=pd.DataFrame(eye_a_f(eye_v,data_part+3),columns=['a'+str(col)]).reset_index(drop=True)\n",
    "                                eye_jerk=pd.DataFrame(eye_j_f(eye_a,data_part+2),columns=['a'+str(col)]).reset_index(drop=True)\n",
    "                                eye_vc=pd.DataFrame(eye_s_c(eye_v,data_part+3),columns=['vc'+str(col)]).reset_index(drop=True)\n",
    "                                eye_ac=pd.DataFrame(eye_s_c(eye_a,data_part+2),columns=['va'+str(col)]).reset_index(drop=True)\n",
    "                                eye_jc=pd.DataFrame(eye_s_c(eye_jerk,data_part+1),columns=['vj'+str(col)]).reset_index(drop=True)\n",
    "                        \n",
    "                                # data scaling - normalization\n",
    "                                scaler = MinMaxScaler()\n",
    "                                eye_v_norm = scaler.fit_transform(eye_v)\n",
    "                                eye_a_norm = scaler.fit_transform(eye_a)\n",
    "                                eye_jerk_norm = scaler.fit_transform(eye_jerk)\n",
    "                                eye_vc_norm = scaler.fit_transform(eye_vc)\n",
    "                                eye_ac_norm = scaler.fit_transform(eye_ac)\n",
    "                                eye_jc_norm = scaler.fit_transform(eye_jc)\n",
    "                        \n",
    "                                # feature calculation for data segments\n",
    "                                f_series,f_value=point_feature_set(segment_length, eye_v_norm,eye_a_norm, eye_jerk_norm,eye_vc_norm, eye_ac_norm, eye_jc_norm)\n",
    "                                                    \n",
    "                                point_feature_series=pd.concat([point_feature_series.reset_index(drop=True), f_series.reset_index(drop=True)], axis=1)\n",
    "                                point_feature_series.columns =['session', 'label', 'trial', 'v', 'a', 'j', 'vc','ac','jc', 'f']\n",
    "                                                        \n",
    "                                # statistical features for the flat model\n",
    "                                point_feature_values = pd.concat([point_feature_values.reset_index(drop=True), f_value.reset_index(drop=True)], axis=1)\n",
    "                                point_feature_values.columns=['session', 'label', 'trial',  'minv', 'maxv', 'avgv', 'stdv','mina', 'maxa', 'avga', 'stda', 'minj', 'maxj', 'avgj', 'stdj', 'minf', 'maxf', 'avgf', 'stdf']\n",
    "                            \n",
    "                           \n",
    "                                # all sessions in one file \n",
    "                                f_series_all=pd.concat([f_series_all, point_feature_series],  axis=0)\n",
    "                                f_values_all=pd.concat([f_values_all, point_feature_values],  axis=0)\n",
    "                            \n",
    "print('completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ac8c3-7e78-468c-88bb-2549e0d23afb",
   "metadata": {},
   "source": [
    "**Time series experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3119b-67cf-418e-a15c-059791e3e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM network classification\n",
    "\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE= 64\n",
    "\n",
    "ACC, F1, CK=[], [], []\n",
    "\n",
    "# Cross-validation\n",
    "for session in range (1,lb_sessions+1):\n",
    "    f_series_train=f_series_all[f_series_all['session']!=str(session)]\n",
    "    f_series_test=f_series_all[f_series_all['session']==str(session)]\n",
    "      \n",
    "    trainSamples_LSTM, trainLabels_LSTM= train_test_set (f_series_train, segment_length, col_number)\n",
    "    testSamples_LSTM, testLabels_LSTM=train_test_set (f_series_test, segment_length, col_number)\n",
    "    \n",
    "    lstm_model= model_LSTM(class_nb, col_number)\n",
    "    \n",
    "    H = lstm_model.fit(tf.convert_to_tensor(trainSamples_LSTM, dtype=tf.float32), trainLabels_LSTM, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE, validation_data=(tf.convert_to_tensor(testSamples_LSTM, dtype=tf.float32), testLabels_LSTM))\n",
    "\n",
    "    modelResults = lstm_model.predict([testSamples_LSTM])\n",
    "    A, F, C = calc_metrics(modelResults, testLabels_LSTM)\n",
    "    ACC.append(A)\n",
    "    F1.append(F)\n",
    "    CK.append(C)\n",
    "\n",
    "metrics_df=pd.concat([pd.DataFrame([[lp, session, EPOCHS]]).reset_index(drop=True), pd.DataFrame(ACC,columns=['ACC']).reset_index(drop=True), pd.DataFrame(F1,columns=['F1']).reset_index(drop=True), pd.DataFrame(CK,columns=['CK']).reset_index(drop=True)], axis=1)\n",
    "metrics_df.to_csv(output_dir+'BE_'+str(lb_sessions)+'_'+str(lp)+'_metrics.csv', sep=';', mode='a', header=True, index=False)          \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021f62f-ddb1-4676-bb2c-3d246298a4e7",
   "metadata": {},
   "source": [
    "**Statistical features experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fa6c4-9215-47b7-9286-e4343b84d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat network classification\n",
    "\n",
    "# Number of layers\n",
    "layers=3\n",
    "\n",
    "ACC_flat, F1_flat, CK_flat=[], [], []\n",
    "\n",
    "# Cross-validation\n",
    "for session in range (1,lb_sessions+1):\n",
    "    f_values_train=f_values_all[f_values_all['session']!=str(session)]\n",
    "    f_values_test=f_values_all[f_values_all['session']==str(session)]\n",
    "    \n",
    "    trainSamples_flat, trainLabels_flat= train_test_set_flat (f_values_train, flat_col_number)\n",
    "    testSamples_flat, testLabels_flat=train_test_set_flat (f_values_test, flat_col_number)\n",
    "    \n",
    "    flat_model=model_flat(class_nb, flat_col_number,layers)\n",
    "\n",
    "    H_flat = flat_model.fit(tf.convert_to_tensor(trainSamples_flat, dtype=tf.float32), trainLabels_flat, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE)\n",
    "\n",
    "    modelResults_flat = flat_model.predict(tf.convert_to_tensor(testSamples_flat, dtype=tf.float32))\n",
    "\n",
    "    A, F, C = calc_metrics(modelResults_flat, testLabels_flat)\n",
    "    ACC_flat.append(A)\n",
    "    F1_flat.append(F)\n",
    "    CK_flat.append(C)\n",
    "\n",
    "\n",
    "metrics_flat_df=pd.concat([pd.DataFrame([[lp, session, EPOCHS]]).reset_index(drop=True), pd.DataFrame(ACC_flat,columns=['ACC']).reset_index(drop=True), pd.DataFrame(F1_flat,columns=['F1']).reset_index(drop=True), pd.DataFrame(CK_flat,columns=['CK']).reset_index(drop=True)], axis=1)\n",
    "metrics_flat_df.to_csv(output_dir+'BE_Flat_'+str(layers)+'L_'+str(lb_sessions)+'_'+str(lp)+'_metrics.csv', sep=';', mode='a', header=True, index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c86b15-aafe-4ef2-bc06-4cd3e8bbf42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
