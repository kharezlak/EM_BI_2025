{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade6d59-36df-4a03-ab95-81551f3fe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,cohen_kappa_score,f1_score\n",
    "\n",
    "from scipy.fft import fft, fftfreq, rfft, rfftfreq, irfft\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f0e04e-ac61-4be5-b32a-81f521eb83aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_set (set_tt, segment_length, col_nb):\n",
    "# Splitting into time series of 100 samples each\n",
    "    samples = [] \n",
    "    labels = [] \n",
    "\n",
    "    col_number=col_nb\n",
    "\n",
    "    samples.append(set_tt.iloc[:, 3:col_number])# [6,7,8,9]]) #3:col_number\n",
    "    labels.append(set_tt.iloc[:,1])\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    labels = np.array(labels).astype(int)\n",
    "\n",
    "    samples = np.squeeze(samples)\n",
    "    labels = np.squeeze(labels)\n",
    "    \n",
    "    noOfFeatures = col_number-3\n",
    "    \n",
    "    samples = samples.reshape(-1,segment_length,noOfFeatures)\n",
    "    labels = np.max(labels.reshape(-1, segment_length), axis=1)\n",
    "    encoder = LabelEncoder()\n",
    "    int_labels = encoder.fit_transform(labels)\n",
    "    numeric_labels = tf.keras.utils.to_categorical(int_labels)\n",
    "\n",
    "    tSamples=samples\n",
    "    tLabels = numeric_labels\n",
    "\n",
    "    return  tSamples, tLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b17a3b-c345-4a17-bdd1-150524af1a98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Velocity calculation\n",
    "def eye_v_f(eye_subset, series_length):\n",
    "# eye_subset - recording of 304 eye movement positions along the x-axis, series_length=304\n",
    "    sig_speed =[]\n",
    "    for i in range (0,series_length-1):\n",
    "        next_i=i+1\n",
    "        speed_one=(eye_subset.iloc[next_i]-eye_subset.iloc[i])*40\n",
    "        sig_speed.append(speed_one)\n",
    "        \n",
    "    return sig_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b309b17-0225-4498-b600-a06c61740440",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Acceleration calculation\n",
    "def eye_a_f(v_subset, series_length):\n",
    "# v_subset - recording of 303 eye movement velocities along the x-axis, series_length=303\n",
    "    sig_acc =[]\n",
    "    for i in range (0,series_length-1):\n",
    "        next_i=i+1\n",
    "        acc_one=v_subset.iloc[next_i,0]-v_subset.iloc[i,0]\n",
    "        sig_acc.append(acc_one)\n",
    "        \n",
    "    return sig_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7c42f-8d38-4c37-84e1-d7ecc849d282",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jerk calculation\n",
    "def eye_j_f(a_subset, series_length):\n",
    "#a_subset - - recording of 303 eye movement acceleration along the x-axis, series_length=30\n",
    "    sig_jerk =[]\n",
    "    for i in range (0,series_length-1):\n",
    "        next_i=i+1\n",
    "        jerk_one=a_subset.iloc[next_i,0]-a_subset.iloc[i,0]\n",
    "        sig_jerk.append(jerk_one)\n",
    "        \n",
    "    return sig_jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e93f83-2320-44a5-9da9-bbbc19b5217a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Percentage changes calculations\n",
    "def eye_s_c(eye_subset, series_length):\n",
    "    sig_percChange =[]\n",
    "    for i in range (0,series_length-1):\n",
    "        next_i=i+1\n",
    "        i1=eye_subset.iloc[next_i].item()\n",
    "        i0=eye_subset.iloc[i].item()\n",
    "        if i0==0:\n",
    "            i0=0.000001\n",
    "        percChange_one=(i1-i0)/i0\n",
    "        sig_percChange.append(percChange_one)\n",
    "    return sig_percChange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223e9d2-04ed-4db0-afe0-e78e893a7281",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def point_feature_set (segment_length, v_subset, a_subset, j_subset, vc_subset, va_subset, vj_subset):\n",
    "    point_fs=pd.DataFrame()\n",
    "    point_fv=pd.DataFrame()\n",
    "    \n",
    "    for segment in range (0,3): \n",
    "        \n",
    "        start_seg=segment*segment_length\n",
    "        \n",
    "        v_segment=pd.DataFrame(v_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        a_segment=pd.DataFrame(a_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        j_segment=pd.DataFrame(j_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        vc_segment=pd.DataFrame(vc_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        va_segment=pd.DataFrame(va_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        vj_segment=pd.DataFrame(vj_subset).iloc[start_seg:start_seg+segment_length]\n",
    "        # Calculation of the Fourier transform\n",
    "        v_segment_np=v_segment.to_numpy()\n",
    "        fft_segment = pd.DataFrame(np.abs(fft(v_segment_np[:,0])))\n",
    "        scaler = MinMaxScaler()\n",
    "        fft_segment_norm = pd.DataFrame(scaler.fit_transform(fft_segment))\n",
    "        \n",
    "        # Feature vector generation â€“ three columns per point, with one 12-feature vector per point\n",
    "        one_segment_df=pd.concat([ v_segment.reset_index(drop=True),a_segment.reset_index(drop=True), j_segment.reset_index(drop=True), \\\n",
    "                           vc_segment.reset_index(drop=True),va_segment.reset_index(drop=True),vj_segment.reset_index(drop=True), fft_segment_norm.reset_index(drop=True)], axis=1)\n",
    "        \n",
    "        point_fs=pd.concat([point_fs.reset_index(drop=True),one_segment_df.reset_index(drop=True)], axis=0) \n",
    "       \n",
    "        # Statistic data calculation\n",
    "        flat_features=pd.Series([float(np.min(v_segment, axis=0)), float(np.max(v_segment, axis=0)), np.average(v_segment), float(np.std(v_segment, axis=0)), \\\n",
    "                                                        float(np.min(a_segment, axis=0)), float(np.max(a_segment, axis=0)), np.average(a_segment), float(np.std(a_segment, axis=0)),\\\n",
    "                                                        float(np.min(j_segment, axis=0)), float(np.max(j_segment, axis=0)), np.average(j_segment), float(np.std(j_segment, axis=0)),\\\n",
    "                                                        float(fft_segment_norm.min()),  float(fft_segment_norm.max()), float(fft_segment_norm.mean()), float(fft_segment_norm.std())])\n",
    "\n",
    "        point_fv = pd.concat([point_fv.reset_index(drop=True), flat_features.to_frame().T], axis=0)\n",
    "        \n",
    "\n",
    "    return  point_fs, point_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a9894-569b-4bce-9dc5-9e559480eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(label_nb, colNb): \n",
    "    class_nb=label_nb\n",
    "    tf.random.set_seed(2)\n",
    "    #del model\n",
    "    time_range = 100\n",
    "    INPUT_SEQUENCE_LEN=time_range\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,input_shape=(INPUT_SEQUENCE_LEN, colNb-3), return_sequences=True)) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(class_nb, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eff90e-c7ae-4782-8021-bf9e16342ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_flat(label_nb, colNb, layers):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(colNb-3,)))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    if (layers>=3):\n",
    "        model.add(Dense(75,  activation='sigmoid'))\n",
    "        if (layers==4):\n",
    "             model.add(Dense(55,  activation='sigmoid'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(label_nb, activation='softmax')) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835e890-b654-4412-b555-c6aef23b720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set_flat(set_tt,col_nb):\n",
    "#for statistical features train_f_values\n",
    "    samples = [] \n",
    "    labels = [] \n",
    "    col_number=col_nb\n",
    "    for x in range(0, set_tt.shape[0]):\n",
    "    \n",
    "        samples.append(set_tt.iloc[x,3:col_number])\n",
    "        labels.append(set_tt.iloc[x,1])\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    labels = np.array(labels).astype(int)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    int_labels = encoder.fit_transform(labels)\n",
    "    numeric_labels = tf.keras.utils.to_categorical(int_labels)\n",
    "\n",
    "    tSamples=samples\n",
    "    tLabels = numeric_labels\n",
    "\n",
    "    return  tSamples, tLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbc134-c8fa-4712-b077-8148a72548aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_metrics(modelResults, testLabels):\n",
    "    \n",
    "    oryginal_arr=testLabels.argmax(axis=1)\n",
    "    u_oryg_labels =np.unique(oryginal_arr)\n",
    "    avg_prob_class=np.zeros(len(u_oryg_labels))\n",
    "         \n",
    "    for i in range(len(u_oryg_labels)):\n",
    "    \n",
    "        indices=np.where(oryginal_arr==u_oryg_labels[i])\n",
    "        rows_nb=len(indices[0])\n",
    "        class_wyb= modelResults[indices,:]\n",
    "        class_avg=np.mean(class_wyb[0,0:rows_nb], axis=0)                          \n",
    "        avg_prob_class[i]=class_avg.argmax()  \n",
    "           \n",
    "    CK=cohen_kappa_score(u_oryg_labels,avg_prob_class)\n",
    "    ACC=accuracy_score(u_oryg_labels,avg_prob_class)\n",
    "    F1=f1_score(u_oryg_labels,avg_prob_class, average='macro')\n",
    "    \n",
    "    return ACC, F1, CK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
